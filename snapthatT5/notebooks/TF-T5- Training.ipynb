{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Hugging Face",
      "language": "python",
      "name": "hugging"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    },
    "colab": {
      "name": "TF-T5- Training.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/snapthat/TF-T5-text-to-text/blob/master/snapthatT5/notebooks/TF-T5-%20Training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MtcZthujDXNp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MNXNDZAfDXNx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sys\n",
        "sys.path.append(\"../../\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6aWoa3AtDXN0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow_datasets as tfds\n",
        "import tensorflow as tf\n",
        "\n",
        "import time\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from language.config.tfgpuconfig import TFGPUConfig\n",
        "import tensorflow_datasets as tfds\n",
        "from transformers import (TFAutoModelWithLMHead, AutoTokenizer, \n",
        "    TFTrainer, TFTrainingArguments, TFT5ForConditionalGeneration, T5Config)\n",
        "import datetime\n",
        "import os"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HW4rT8FODXN3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "os.environ[\"TF_GPU_THREAD_MODE\"]=\"gpu_private\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OQ5CoTk-DXN6",
        "colab_type": "code",
        "colab": {},
        "outputId": "e10031cf-7e75-4012-e4a4-7ac3ecee9d1e"
      },
      "source": [
        "tf.__version__"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.3.0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0X5jKZMdDXN9",
        "colab_type": "code",
        "colab": {},
        "outputId": "d9f201a1-18ea-4127-b14c-d72eb36715e4"
      },
      "source": [
        "tfgpu_config = TFGPUConfig()\n",
        "tfgpu_config.select_gpus([0])  # select gpu\n",
        "tfgpu_config.set_gpu_memory_growth()\n",
        "print(f\"Total physical gpus: {tfgpu_config.get_physical_gpu_count()}\")\n",
        "print(f\"Total Logical gpus: {tfgpu_config.get_logical_gpu_count()}\")\n",
        "print(f\"Selected GPU: {tfgpu_config.get_selected_gpus()}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total physical gpus: 1\n",
            "Total Logical gpus: 1\n",
            "Selected GPU: ['/physical_device:GPU:0']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KRMGSskHDXOA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "log_dir = \"/home/ml/workspace/ai/language-modelling/data/experiments/t5/logs\"\n",
        "save_path = \"/home/ml/workspace/ai/language-modelling/data/experiments/t5/models\"\n",
        "cache_path_train = \"/home/ml/workspace/ai/language-modelling/data/cache/t5.train\"\n",
        "cache_path_test = \"/home/ml/workspace/ai/language-modelling/data/cache/t5.test\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VvOrIgzODXOD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(\"t5-base\")          "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2xcGqd9qDXOF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class SnapthatT5(TFT5ForConditionalGeneration):\n",
        "    def __init__(self, *args, log_dir=None, cache_dir= None, **kwargs):\n",
        "        super().__init__(*args, **kwargs)\n",
        "        self.loss_tracker= tf.keras.metrics.Mean(name='loss')\n",
        "#         self.test_loss_tracker= tf.keras.metrics.Mean(name='val_loss')     \n",
        "        pass\n",
        "    \n",
        "    def train_step(self, data):\n",
        "        x, y  = data\n",
        "        with tf.GradientTape() as tape:\n",
        "            outputs = model(x, training=True)\n",
        "            loss = outputs[0]\n",
        "            logits = outputs[1]\n",
        "            loss = tf.reduce_mean(loss)\n",
        "            \n",
        "        grads = tape.gradient(loss, model.trainable_variables)\n",
        "        self.optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
        "        lr = optimizer.lr\n",
        "        \n",
        "        self.loss_tracker.update_state(loss)\n",
        "        \n",
        "        self.compiled_metrics.update_state(y, logits)\n",
        "        metrics = {m.name: m.result() for m in self.metrics}\n",
        "        metrics.update({'lr': lr})\n",
        "        \n",
        "        return metrics\n",
        "\n",
        "    def test_step(self, data):\n",
        "        # Unpack the data\n",
        "        x, y = data\n",
        "        # Compute predictions\n",
        "        output = self(x, training=False)\n",
        "        loss = output[0]\n",
        "        loss = tf.reduce_mean(loss)\n",
        "        logits = output[1]\n",
        "        \n",
        "        self.loss_tracker.update_state(loss)\n",
        "        self.compiled_metrics.update_state(y, logits)\n",
        "        return {m.name: m.result() for m in self.metrics}\n",
        "\n",
        "        "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1EgTphQODXOH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "KX1rsWgZDXOK",
        "colab_type": "code",
        "colab": {},
        "outputId": "8967c22c-732a-422f-9e1d-8462d23ecb0f"
      },
      "source": [
        "train_dataset, info = tfds.load('squad', split='train', with_info=True)\n",
        "valid_dataset = tfds.load('squad', split='validation', with_info=False)\n",
        "print(info)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:absl:No config specified, defaulting to first: squad/plain_text\n",
            "INFO:absl:Load dataset info from /home/ml/tensorflow_datasets/squad/plain_text/1.0.0\n",
            "INFO:absl:Reusing dataset squad (/home/ml/tensorflow_datasets/squad/plain_text/1.0.0)\n",
            "INFO:absl:Constructing tf.data.Dataset for split train, from /home/ml/tensorflow_datasets/squad/plain_text/1.0.0\n",
            "INFO:absl:No config specified, defaulting to first: squad/plain_text\n",
            "INFO:absl:Load dataset info from /home/ml/tensorflow_datasets/squad/plain_text/1.0.0\n",
            "INFO:absl:Reusing dataset squad (/home/ml/tensorflow_datasets/squad/plain_text/1.0.0)\n",
            "INFO:absl:Constructing tf.data.Dataset for split validation, from /home/ml/tensorflow_datasets/squad/plain_text/1.0.0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "tfds.core.DatasetInfo(\n",
            "    name='squad',\n",
            "    version=1.0.0,\n",
            "    description='Stanford Question Answering Dataset (SQuAD) is a reading comprehension dataset, consisting of questions posed by crowdworkers on a set of Wikipedia articles, where the answer to every question is a segment of text, or span, from the corresponding reading passage, or the question might be unanswerable.',\n",
            "    homepage='https://rajpurkar.github.io/SQuAD-explorer/',\n",
            "    features=FeaturesDict({\n",
            "        'answers': Sequence({\n",
            "            'answer_start': tf.int32,\n",
            "            'text': Text(shape=(), dtype=tf.string),\n",
            "        }),\n",
            "        'context': Text(shape=(), dtype=tf.string),\n",
            "        'id': tf.string,\n",
            "        'question': Text(shape=(), dtype=tf.string),\n",
            "        'title': Text(shape=(), dtype=tf.string),\n",
            "    }),\n",
            "    total_num_examples=98169,\n",
            "    splits={\n",
            "        'train': 87599,\n",
            "        'validation': 10570,\n",
            "    },\n",
            "    supervised_keys=None,\n",
            "    citation=\"\"\"@article{2016arXiv160605250R,\n",
            "           author = {{Rajpurkar}, Pranav and {Zhang}, Jian and {Lopyrev},\n",
            "                     Konstantin and {Liang}, Percy},\n",
            "            title = \"{SQuAD: 100,000+ Questions for Machine Comprehension of Text}\",\n",
            "          journal = {arXiv e-prints},\n",
            "             year = 2016,\n",
            "              eid = {arXiv:1606.05250},\n",
            "            pages = {arXiv:1606.05250},\n",
            "    archivePrefix = {arXiv},\n",
            "           eprint = {1606.05250},\n",
            "    }\"\"\",\n",
            "    redistribution_info=,\n",
            ")\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y7EK-tgHDXOM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SIZFbP4IDXOO",
        "colab_type": "code",
        "colab": {},
        "outputId": "7e5e1ad2-fdd7-448b-c32a-71208ddfa158"
      },
      "source": [
        "warmup_steps = 1e4\n",
        "batch_size = 4\n",
        "max_len = 100\n",
        "buffer_size = 1000\n",
        "ntrain = info.splits[\"train\"].num_examples\n",
        "nvalid = info.splits[\"validation\"].num_examples\n",
        "steps = int(np.ceil(ntrain/batch_size))\n",
        "valid_steps = int(np.ceil(nvalid/batch_size))\n",
        "print(\"Total Steps: \", steps)\n",
        "print(\"Total Validation Steps: \", valid_steps)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total Steps:  21900\n",
            "Total Validation Steps:  2643\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NFg4KrtcDXOR",
        "colab_type": "code",
        "colab": {},
        "outputId": "b735ace0-4015-4fb6-bc4c-f77e6a56073f"
      },
      "source": [
        "for example in train_dataset.skip(5):\n",
        "    print(example.keys())\n",
        "    context = example['context']\n",
        "    question = example['question']\n",
        "#     print(f\"Answers: {example['answers']}\")\n",
        "    print(f\"context: {context}\")\n",
        "#     print(f\"id: {example['id']}\")\n",
        "#     print(f\"question: {question}\")\n",
        "#     print(f\"title: {example['title']}\")\n",
        "    break"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dict_keys(['answers', 'context', 'id', 'question', 'title'])\n",
            "context: b\"Similarly, movies and television often revert to standard, clich\\xc3\\xa9d snatches of classical music to convey refinement or opulence: some of the most-often heard pieces in this category include Bach\\xc2\\xb4s Cello Suite No. 1, Mozart's Eine kleine Nachtmusik, Vivaldi's Four Seasons, Mussorgsky's Night on Bald Mountain (as orchestrated by Rimsky-Korsakov), and Rossini's William Tell Overture.\"\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "r2Oe1BmfDXOU",
        "colab_type": "code",
        "colab": {},
        "outputId": "d7fecd9d-06d9-42d8-a8b2-dace7b8beb00"
      },
      "source": [
        "context_plus = f\"ask_question: {str(context.numpy().decode('utf-8'))} </s>\"\n",
        "question_plus = f\"{str(question.numpy().decode('utf-8'))} </s>\"\n",
        "encoded = tokenizer(context_plus, padding=True, truncation=True, return_tensors='tf', \n",
        "                   max_length=512)\n",
        "\n",
        "encoded_plus = tokenizer([question_plus], truncation=True,\n",
        "                                    return_tensors='tf', max_length=512, \n",
        "                                    pad_to_max_length=True)\n",
        "encoded_plus"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': <tf.Tensor: shape=(1, 512), dtype=int32, numpy=\n",
              "array([[2645, 2832, 4599, 8779, 2035, 2693,   58,    1,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0]], dtype=int32)>, 'attention_mask': <tf.Tensor: shape=(1, 512), dtype=int32, numpy=\n",
              "array([[1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0]], dtype=int32)>}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4WSGU81JDXOW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NdhcP171DXOY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def encode(context,question , max_length=max_len):\n",
        "    context_plus = f\"ask_question: {str(context.numpy().decode('utf-8'))} </s>\"\n",
        "    question_plus = f\"{str(question.numpy().decode('utf-8'))} </s>\"\n",
        "    \n",
        "    encoder_inputs = tokenizer(context_plus, truncation=True, \n",
        "                               return_tensors='tf', max_length=max_length,\n",
        "                              pad_to_max_length=True)\n",
        "    \n",
        "    decoder_inputs = tokenizer(question_plus, truncation=True, \n",
        "                               return_tensors='tf', max_length=max_length,\n",
        "                              pad_to_max_length=True)\n",
        "    \n",
        "    input_ids = encoder_inputs['input_ids'][0]\n",
        "    input_attention = encoder_inputs['attention_mask'][0]\n",
        "    target_ids = decoder_inputs['input_ids'][0]\n",
        "    target_attention = decoder_inputs['attention_mask'][0]\n",
        "    \n",
        "    return input_ids,input_attention, target_ids, target_attention\n",
        "    \n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-sdlkpyEDXOa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def encode_tf(inputs):\n",
        "    context = inputs['context']\n",
        "    question = inputs['question']\n",
        "    input_ids,input_attention, target_ids,target_attention = tf.py_function(encode, [context, question], \n",
        "                                           [tf.int32, tf.int32, tf.int32, tf.int32])\n",
        "    input_ids.set_shape([None])\n",
        "    target_ids.set_shape([None])\n",
        "    input_attention.set_shape([None])\n",
        "    target_attention.set_shape([None])\n",
        "    \n",
        "    labels = tf.reshape(target_ids, [-1, 1])\n",
        "    data=  {'input_ids': input_ids, #'decoder_input_ids': target_ids, \n",
        "            'labels': target_ids, \n",
        "            'attention_mask': input_attention,\n",
        "           'decoder_attention_mask': target_attention}\n",
        "    return (data, labels)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LUKypEaSDXOd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_dataset(source_dataset, cache_path=None, batch_size=4, \n",
        "                   buffer_size= 1000, shuffling=True):\n",
        "    dataset = source_dataset.map(encode_tf, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "    \n",
        "    if cache_path is not None:\n",
        "        dataset = dataset.cache(cache_path)        \n",
        "    if shuffling:\n",
        "        dataset = dataset.shuffle(buffer_size)\n",
        "    dataset = dataset.batch(batch_size)\n",
        "    dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
        "    return dataset\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nNiNtnsHDXOf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_ds= create_dataset(train_dataset, batch_size=batch_size, \n",
        "                         shuffling=True, cache_path = None)\n",
        "valid_ds = create_dataset(valid_dataset, batch_size=batch_size, \n",
        "                         shuffling=False, cache_path = None)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "KL9VfwI6DXOh",
        "colab_type": "code",
        "colab": {},
        "outputId": "09cd331a-338c-43c7-d0cd-1a22e685232a"
      },
      "source": [
        "data = next(iter(train_ds))\n",
        "data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "({'input_ids': <tf.Tensor: shape=(4, 100), dtype=int32, numpy=\n",
              "  array([[  987,   834,  7771,  1575,    10,    37, 12729,    19,     3,\n",
              "              9,  1745,  1208,   538,    28,   128, 11552,    20,  4571,\n",
              "            162,    26,    12,  4593,  3141,  5579,     7,    41,   434,\n",
              "          13961,     7,    61,   365,     8,  1353,    13,     8,  4593,\n",
              "           3141,  3636,     5,   290,    19,    92,    80, 21286,  1719,\n",
              "              6,     8,  2040,  3114,  1162,  6163,    13, 10148,  8477,\n",
              "            152,     9,    32,     5,  2035,     8,   203,   796, 14172,\n",
              "             43,   118,  4382,    12,     8, 11378,    13,     8, 12729,\n",
              "              6,   379,   487,  3508,    12,     3,     9,  2822,   358,\n",
              "             38,   294,    13,     3,     9,  4108,    12,     3,     9,\n",
              "              3, 28443,   358,     5,    86, 16931, 27233,  1661, 29678,\n",
              "           2143],\n",
              "         [  987,   834,  7771,  1575,    10,   461,  1671, 12026,  1003,\n",
              "           3914,     6,  1117,  5089,  1632,     8,     3,    17,  9803,\n",
              "             89,   189,   538,    12,     3,  1795,  4921,     8, 11378,\n",
              "              5,    86,   507,  2445,     6,    34,  2012,     8,   538,\n",
              "          23491,   740,    16, 27414,     6,   341,  4125,   469,     5,\n",
              "           1377,    13,  1117,  5089,    31,     7, 15484,  2713,    11,\n",
              "            508,  1475,  1628,   130,  1069,    16,     8, 13350,  4149,\n",
              "             13,     8,   538,     5,  1875,  1117,  5089,    31,     7,\n",
              "           1475,   257,   358,    47,  2755,    11,   705, 29137,   145,\n",
              "             24,    13,  5382,     6,  5664,     6,    42,  1013,  5089,\n",
              "              6,  1516,  2302,    13,  1475,   277,   130, 18054,    16,\n",
              "              8],\n",
              "         [  987,   834,  7771,  1575,    10,    37,  2084,    13,     8,\n",
              "            778, 14877,  6490,    24,   925,    26,    26,   107,     2,\n",
              "             52,   189,     9, 12520, 22713,    47,  2170,    16,     3,\n",
              "              9,   573,    24,    47,    30,     8,   158,  5082,   760,\n",
              "             63,     6,   321, 20187,   120,    11,  2779,   120,     6,\n",
              "             13,     8, 25806,    49,    29,  2557,   769, 27339,    16,\n",
              "              8,  8486,  2646,   272,  4770,     5,    94,    47,   893,\n",
              "              3,     9,   422, 20237,     6,    16,    84,   495,   112,\n",
              "           2353,    47,    46,  8160,  5752,    17,     9,    77,     6,\n",
              "             42,    46,     3,  4172,  1478, 11971,     6,    16,    84,\n",
              "            495,   112,  2353,    47,    46,     3,    32,  2825,  7064,\n",
              "              5],\n",
              "         [  987,   834,  7771,  1575,    10,   938,     8,  4551,  7526,\n",
              "              7,     6,   508,  2302,    13, 11896,  4114,    16,     8,\n",
              "           6679,  3385, 12187,    11,   141,     3,  6500, 26759,  1054,\n",
              "            139,  2968,  1543,     6,   379,   186, 11896,   113,   141,\n",
              "           3150,     3,  6500, 26759,  1054,   139,  2379,  1543,    11,\n",
              "            141, 11518,     3,     9,  4838, 15028,    32,    18,   371,\n",
              "             60,  5457,  1612,     5,     3, 10688,     3,  6500, 26759,\n",
              "           1222,   139,  2968,  1543,     6,     8,  6692,  2968,   151,\n",
              "              7,     3, 10975,   779,  1467,    13,     8,  2968,  1612,\n",
              "             11,  2479,    13,   119,  1611,  8024,   139,     3,     9,\n",
              "           4838,  1612,   801,    38, 14224,    26,    26,  1273,     5,\n",
              "            611]], dtype=int32)>,\n",
              "  'labels': <tf.Tensor: shape=(4, 100), dtype=int32, numpy=\n",
              "  array([[  363,   410,  1661, 29678,  2143,  9750,  6191,  1533,  8170,\n",
              "             32,  4797,    58,     1,     0,     0,     0,     0,     0,\n",
              "              0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "              0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "              0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "              0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "              0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "              0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "              0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "              0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "              0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "              0],\n",
              "         [  363,   294,    13,     8,   538,   130,   167, 15484,    11,\n",
              "           1475,   257,  2713, 18054,    16,    58,     1,     0,     0,\n",
              "              0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "              0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "              0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "              0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "              0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "              0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "              0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "              0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "              0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "              0],\n",
              "         [  156,   925,    26,    26, 13626,  1024,  4114,    16,     3,\n",
              "              9,   422, 20237,     6,   112,  2353,   133,    43,   118,\n",
              "              3,     9,   125,    58,     1,     0,     0,     0,     0,\n",
              "              0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "              0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "              0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "              0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "              0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "              0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "              0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "              0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "              0],\n",
              "         [  938,   125,    97,  1059,   141,   186,    13,     8,  6692,\n",
              "           2074,  3311,     8,  6679,  3385, 12187,    58,     1,     0,\n",
              "              0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "              0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "              0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "              0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "              0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "              0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "              0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "              0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "              0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "              0]], dtype=int32)>,\n",
              "  'attention_mask': <tf.Tensor: shape=(4, 100), dtype=int32, numpy=\n",
              "  array([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
              "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
              "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
              "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], dtype=int32)>,\n",
              "  'decoder_attention_mask': <tf.Tensor: shape=(4, 100), dtype=int32, numpy=\n",
              "  array([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "          1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], dtype=int32)>},\n",
              " <tf.Tensor: shape=(4, 100, 1), dtype=int32, numpy=\n",
              " array([[[  363],\n",
              "         [  410],\n",
              "         [ 1661],\n",
              "         [29678],\n",
              "         [ 2143],\n",
              "         [ 9750],\n",
              "         [ 6191],\n",
              "         [ 1533],\n",
              "         [ 8170],\n",
              "         [   32],\n",
              "         [ 4797],\n",
              "         [   58],\n",
              "         [    1],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0]],\n",
              " \n",
              "        [[  363],\n",
              "         [  294],\n",
              "         [   13],\n",
              "         [    8],\n",
              "         [  538],\n",
              "         [  130],\n",
              "         [  167],\n",
              "         [15484],\n",
              "         [   11],\n",
              "         [ 1475],\n",
              "         [  257],\n",
              "         [ 2713],\n",
              "         [18054],\n",
              "         [   16],\n",
              "         [   58],\n",
              "         [    1],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0]],\n",
              " \n",
              "        [[  156],\n",
              "         [  925],\n",
              "         [   26],\n",
              "         [   26],\n",
              "         [13626],\n",
              "         [ 1024],\n",
              "         [ 4114],\n",
              "         [   16],\n",
              "         [    3],\n",
              "         [    9],\n",
              "         [  422],\n",
              "         [20237],\n",
              "         [    6],\n",
              "         [  112],\n",
              "         [ 2353],\n",
              "         [  133],\n",
              "         [   43],\n",
              "         [  118],\n",
              "         [    3],\n",
              "         [    9],\n",
              "         [  125],\n",
              "         [   58],\n",
              "         [    1],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0]],\n",
              " \n",
              "        [[  938],\n",
              "         [  125],\n",
              "         [   97],\n",
              "         [ 1059],\n",
              "         [  141],\n",
              "         [  186],\n",
              "         [   13],\n",
              "         [    8],\n",
              "         [ 6692],\n",
              "         [ 2074],\n",
              "         [ 3311],\n",
              "         [    8],\n",
              "         [ 6679],\n",
              "         [ 3385],\n",
              "         [12187],\n",
              "         [   58],\n",
              "         [    1],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0],\n",
              "         [    0]]], dtype=int32)>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "APrEPnW0DXOk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# outputs = model(data[0])\n",
        "# print(\"outputs len: \", len(outputs))\n",
        "# print(outputs[0].shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fpihSQNuDXOm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class CustomScheduleCallback(tf.keras.callbacks.Callback):\n",
        "    def __init__(self, warmup_steps=1e4):\n",
        "        super().__init__()\n",
        "        self.warmup_steps =warmup_steps\n",
        "    \n",
        "    def calcualte_lr(self, step):\n",
        "        step = tf.cast(step, tf.float32)\n",
        "        m = tf.maximum(self.warmup_steps, step)\n",
        "        m = tf.cast(m, tf.float32)\n",
        "        lr = tf.math.rsqrt(m)\n",
        "        return lr\n",
        "    \n",
        "    def on_train_batch_end(self, step, logs=None):\n",
        "        optimizer = self.model.optimizer\n",
        "        itr = optimizer.iterations\n",
        "        scheduled_lr = self.calcualte_lr(itr)        \n",
        "        tf.keras.backend.set_value(optimizer.lr, scheduled_lr)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xHq71CTDDXOn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
        "  def __init__(self, warmup_steps=1e4, schedule=True, initial_lr = 1e-3):\n",
        "    super().__init__()\n",
        "\n",
        "    self.warmup_steps = tf.cast(warmup_steps, tf.float32)\n",
        "    \n",
        "  def __call__(self, step):\n",
        "    step = tf.cast(step, tf.float32)\n",
        "    m = tf.maximum(self.warmup_steps, step)\n",
        "    m = tf.cast(m, tf.float32)\n",
        "    lr = tf.math.rsqrt(m)\n",
        "    \n",
        "    return lr \n",
        "        "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rA9OVe28DXOq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# steps = 150\n",
        "# valid_steps = 150\n",
        "start_profile_batch = steps+10\n",
        "stop_profile_batch = start_profile_batch + 100\n",
        "profile_range = f\"{start_profile_batch},{stop_profile_batch}\"\n",
        "\n",
        "log_path = log_dir + \"/\" + datetime.datetime.now().strftime(\"%Y-%m-%d_%H:%M:%S\")\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_path, histogram_freq=1,\n",
        "                                                     update_freq=20,profile_batch=profile_range)\n",
        "\n",
        "checkpoint_filepath = save_path + \"/\" + \"T5-{epoch:04d}-{val_loss:.4f}.ckpt\"\n",
        "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_filepath,\n",
        "    save_weights_only=False,\n",
        "    monitor='val_loss',\n",
        "    mode='min',\n",
        "    save_best_only=False)\n",
        "\n",
        "custom_schedule_callback = CustomScheduleCallback(warmup_steps)\n",
        "\n",
        "# print(log_path)\n",
        "# custom_logger_callback = CutomLoggerCallback(log_dir)\n",
        "callbacks = [tensorboard_callback, model_checkpoint_callback] # custom_schedule_callback\n",
        "metrics = [tf.keras.metrics.SparseTopKCategoricalAccuracy(name='accuracy') ]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G6-LcG6TDXOt",
        "colab_type": "code",
        "colab": {},
        "outputId": "26461795-21ed-418e-d843-415152d291ec"
      },
      "source": [
        "plt.style.use('ggplot')\n",
        "schedule = CustomSchedule()\n",
        "plt.plot(schedule(tf.range(25000, dtype=tf.float32)))\n",
        "plt.xlabel(\"Steps\")\n",
        "plt.ylabel(\"Learning rate\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'Learning rate')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SX_CQGhoDXOw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# learning_rate = CustomSchedule()\n",
        "learning_rate = 0.001\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J2vcCZyyDXOy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AZym7SmWDXO0",
        "colab_type": "code",
        "colab": {},
        "outputId": "a2d7251a-59e9-4058-ef95-cde31265c8e2"
      },
      "source": [
        "# model = SnapthatT5.from_pretrained(save_path)\n",
        "model = SnapthatT5.from_pretrained(\"t5-base\")\n",
        "# config = T5Config.from_json_file(\"/home/ml/workspace/ai/language-modelling/data/experiments/t5/models/config.json\")\n",
        "# model = SnapthatT5(config)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:transformers.modeling_tf_utils:All model checkpoint weights were used when initializing SnapthatT5.\n",
            "\n",
            "WARNING:transformers.modeling_tf_utils:Some weights of SnapthatT5 were not initialized from the model checkpoint at t5-base and are newly initialized: ['loss']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z_QxL8gPDXO1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer=optimizer, metrics=metrics)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H-pR7ApEDXO3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# model.save_pretrained(save_path)\n",
        "# model.load_weights(checkpoint_filepath)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "x8QOVpFxDXO5",
        "colab_type": "code",
        "colab": {},
        "outputId": "9e187954-459a-4770-f383-a1501b21e90f"
      },
      "source": [
        "epochs_done = 0\n",
        "model.fit(train_ds, epochs=50, steps_per_epoch=steps, callbacks=callbacks, \n",
        "          validation_data=valid_ds, validation_steps=valid_steps, initial_epoch=epochs_done)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/home/ml/anaconda3/envs/hugging/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:432: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
            "/home/ml/anaconda3/envs/hugging/lib/python3.7/site-packages/transformers/tokenization_utils_base.py:1768: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            " 4305/21900 [====>.........................] - ETA: 2:07:09 - accuracy: 0.9583 - loss: 0.3908 - lr: 0.0010"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-36-1e56b2793c49>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mepochs_done\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m model.fit(train_ds, epochs=50, steps_per_epoch=steps, callbacks=callbacks, \n\u001b[0;32m----> 3\u001b[0;31m           validation_data=valid_ds, validation_steps=valid_steps, initial_epoch=epochs_done)\n\u001b[0m",
            "\u001b[0;32m~/anaconda3/envs/hugging/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/envs/hugging/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/envs/hugging/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/envs/hugging/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    805\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 807\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    808\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/envs/hugging/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2829\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2831\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/envs/hugging/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1846\u001b[0m                            resource_variable_ops.BaseResourceVariable))],\n\u001b[1;32m   1847\u001b[0m         \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m         cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/envs/hugging/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1922\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1923\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1924\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1926\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/envs/hugging/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    548\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m~/anaconda3/envs/hugging/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pDIaNYrVDXO7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# model.evaluate(valid_ds, steps=valid_steps)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nYDPH77LDXO9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save_pretrained(\"/root/language-modelling/data/experiments/t5/models/T5-0022-0.2429\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ihk1kxxDXO_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "encoded_query = tokenizer(\"summarize: object detection </s>\", \n",
        "                         return_tensors='tf', padding=True, truncation=True)\n",
        "input_ids = encoded_query[\"input_ids\"]\n",
        "attention_mask = encoded_query[\"attention_mask\"]\n",
        "generated_question = model.generate(input_ids, attention_mask=attention_mask)\n",
        "decoded_question = tokenizer.decode(generated_question.numpy()[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EejrdGS6DXPB",
        "colab_type": "code",
        "colab": {},
        "outputId": "f2747344-4e8d-4794-8d92-00f4a6f87616"
      },
      "source": [
        "decoded_question"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'object detection is object detection?'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c7VSv5o-DXPD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "no_questions = 5\n",
        "encoded_query = tokenizer(\"ask_question: beards </s>\", \n",
        "                         return_tensors='tf', truncation=True, \n",
        "                          pad_to_max_length=max_len)\n",
        "input_ids = encoded_query[\"input_ids\"]\n",
        "attention_mask = encoded_query[\"attention_mask\"]\n",
        "generated_question = model.generate(input_ids, attention_mask=attention_mask,\n",
        "                                   do_sample=True, max_length=max_len, top_p=0.98, top_k=50,\n",
        "                                   num_return_sequences=no_questions, repetition_penalty=5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QbZ4RObJDXPF",
        "colab_type": "code",
        "colab": {},
        "outputId": "6cf1ff95-096c-4fcf-eb8a-633d24c42d79"
      },
      "source": [
        "for en_question in list(generated_question):\n",
        "    decoded_question = tokenizer.decode(en_question.numpy())\n",
        "    print(decoded_question)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "What is the other important way that humans are asked to be placed in a concert?\n",
            "When was the first one of which other signs criticized by beers forbiding indentenent and mistruth?\n",
            "How many ducks spawned for the first time?\n",
            "When are the reds introduced?\n",
            "What type of animal has been raised by a male group in The A-R?\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IfQmkJyqDXPI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hFUGHduFDXPK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gRuos-M-DXPM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}